{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "13543Lv0qI85903uizlg2EzwF7L6bcJNb",
      "authorship_tag": "ABX9TyMzGb5KW1ypJ63vHWRrSUK0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yclipse/RTS_mapping/blob/main/eeify_and_host_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3iYezYbzLDS",
        "outputId": "ca2311ad-2df0-406f-d28b-89b0643138a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras_unet_collection\n",
            "  Downloading keras_unet_collection-0.1.13-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras_unet_collection\n",
            "Successfully installed keras_unet_collection-0.1.13\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_unet_collection\n",
        "from keras_unet_collection import models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHnsf8QU2GbS",
        "outputId": "fa9ac890-3e06-4893-d98f-372927901e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=NNCMxD6I9PX4zbYUZx3wDM9N27eL3YvPH0Yy2MEXJRU&tc=LNjk4F1QMwDWCttfM9NZVcYhSr2HeeuAhLevHSgM_XQ&cc=PvedWa35s_8ScwOEYLBYJTfYj-z89frm6_4ftlC0G94\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below.\n",
            "Enter verification code: 4/1AbUR2VNGc2pUpDAozf8Tu0l3YLbJZSrlh_VbW7InHTv14GfgEibPn7oSiKg\n",
            "\n",
            "Successfully saved authorization token.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load model"
      ],
      "metadata": {
        "id": "9q2ln4_1zie1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('/content/drive/MyDrive/RTS_models/MODEL_V2_UNET3+_MAXAR_192x192/20230601-161139/params.json', 'r') as f:\n",
        "  PARAMS = json.load(f)\n",
        "\n",
        "model = models.unet_3plus_2d(input_size=PARAMS['model']['input_size'],\n",
        "                  n_labels=2,\n",
        "                  filter_num_down=PARAMS['model']['filter_num'],\n",
        "                  filter_num_skip='auto',\n",
        "                  filter_num_aggregate='auto',\n",
        "                  stack_num_down=PARAMS['model']['stack_num_down'],\n",
        "                  stack_num_up=PARAMS['model']['stack_num_up'],\n",
        "                  activation=PARAMS['model']['activation'],\n",
        "                  output_activation=PARAMS['model']['out_activ'],\n",
        "                  batch_norm=PARAMS['model']['batch_norm'],\n",
        "                  pool=PARAMS['model']['pooling'],\n",
        "                  unpool=PARAMS['model']['unpool'],\n",
        "                  deep_supervision=PARAMS['model']['deep_supervision'],\n",
        "                  backbone=PARAMS['model']['backbone'],\n",
        "                  weights=None,\n",
        "                  freeze_backbone=PARAMS['model']['freeze_backbone'],\n",
        "                  freeze_batch_norm=PARAMS['model']['freeze_bn'],\n",
        "                  name='unet3plus')\n",
        "\n",
        "# Load trained weights\n",
        "model_path = '/content/drive/MyDrive/RTS_models/MODEL_V2_UNET3+_MAXAR_192x192/20230601-161139/cp-0109-valiou0.711.ckpt'\n",
        "model.load_weights(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jeiMrEczkc-",
        "outputId": "3dca264c-4e4d-4c1e-f667-5d5141c28b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automated hyper-parameter determination is applied with the following details:\n",
            "----------\n",
            "\tNumber of convolution filters after each full-scale skip connection: filter_num_skip = [32, 32, 32, 32]\n",
            "\tNumber of channels of full-scale aggregated feature maps: filter_num_aggregate = 160\n",
            "----------\n",
            "deep_supervision = True\n",
            "names of output tensors are listed as follows (\"sup0\" is the shallowest supervision layer;\n",
            "\"final\" is the final output layer):\n",
            "\n",
            "\tunet3plus_output_sup0_activation\n",
            "\tunet3plus_output_sup1_activation\n",
            "\tunet3plus_output_sup2_activation\n",
            "\tunet3plus_output_sup3_activation\n",
            "\tunet3plus_output_final_activation\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f40fe744130>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=PARAMS['train']['learning_rate'],\n",
        "                  beta_1=0.9,\n",
        "                  beta_2=0.999,\n",
        "                  epsilon=PARAMS['train']['adam_epsilon'],\n",
        "                  amsgrad=PARAMS['train']['amsgrad'],\n",
        "                  name='Adam')\n",
        "\n",
        "# sgd = tf.keras.optimizers.SGD(learning_rate=PARAMS['train']['learning_rate'], momentum=0.9)\n",
        "\n",
        "loss = tf.keras.losses.BinaryFocalCrossentropy(\n",
        "    apply_class_balancing=True,\n",
        "    alpha=PARAMS['train']['focal_loss_alpha'],    #In practice α may be set by inverse class frequency or treated as a hyperparameter to set by cross validation\n",
        "    gamma=2,    #dont change\n",
        "    from_logits=False,\n",
        "    label_smoothing=PARAMS['train']['label_smoothing'],\n",
        "    axis=-1,\n",
        "    reduction=tf.keras.losses.Reduction.AUTO,\n",
        "    name='binary_focal_crossentropy'\n",
        ")\n",
        "\n",
        "iou = [tf.keras.metrics.OneHotMeanIoU(num_classes=2, name='iou')]\n",
        "\n",
        "model.compile(loss=loss,\n",
        "       optimizer=adam,\n",
        "       metrics=iou,\n",
        "       )"
      ],
      "metadata": {
        "id": "zTWaSa2U08lF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EEify the model"
      ],
      "metadata": {
        "id": "IY2YQY8fzz-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "MODEL_DIR = '/content/drive/MyDrive/RTS_models/Deployed_Models'\n",
        "MODEL_NAME = 'Unet3_MAXAR192_20230601_161139' #only underscores\n",
        "model.save(os.path.join(MODEL_DIR, MODEL_NAME+'.tf'), save_format='tf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59A7om74zyYv",
        "outputId": "ab1e6688-7416-4fcf-862e-edf2509aee70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 223). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.tools import saved_model_utils\n",
        "\n",
        "meta_graph_def = saved_model_utils.get_meta_graph_def(os.path.join(MODEL_DIR, MODEL_NAME+'.tf'), 'serve')\n",
        "inputs = meta_graph_def.signature_def['serving_default'].inputs\n",
        "outputs = meta_graph_def.signature_def['serving_default'].outputs\n",
        "\n",
        "# Just get the first thing(s) from the serving signature def.  i.e. this\n",
        "# model only has a single input and a single output.\n",
        "input_name = None\n",
        "for k,v in inputs.items():\n",
        "  input_name = v.name\n",
        "  break\n",
        "\n",
        "output_name = None\n",
        "for k,v in outputs.items():\n",
        "  output_name = v.name\n",
        "  break\n",
        "\n",
        "# Make a dictionary that maps Earth Engine outputs and inputs to\n",
        "# AI Platform inputs and outputs, respectively.\n",
        "import json\n",
        "input_dict = \"'\" + json.dumps({input_name: \"array\"}) + \"'\"\n",
        "output_dict = \"'\" + json.dumps({output_name: \"output\"}) + \"'\"\n",
        "print(input_dict)\n",
        "print(output_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C93OK1j1JTV",
        "outputId": "243f9e50-1d6d-40a5-84d8-0eccb7ca4efe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'{\"serving_default_input_2:0\": \"array\"}'\n",
            "'{\"StatefulPartitionedCall:0\": \"output\"}'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Put the EEified model next to the trained model directory.\n",
        "EEIFIED_DIR = os.path.join(MODEL_DIR, MODEL_NAME+'_EEify')\n",
        "PROJECT = 'abruptthawmapping'\n",
        "REGION = 'us-east4'\n",
        "VERSION_NAME = 'v3'\n",
        "STAGING_BUCKET = 'gs://abrupt_thaw'\n",
        "\n",
        "!gcloud config set project {PROJECT}\n",
        "# You need to set the project before using the model prepare command.\n",
        "!earthengine set_project {PROJECT}\n",
        "!earthengine model prepare --source_dir {os.path.join(MODEL_DIR, MODEL_NAME+'.tf')} --dest_dir {EEIFIED_DIR} --input {input_dict} --output {output_dict}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VYU57Qp1hHE",
        "outputId": "af21af78-0716-4a55-efaf-9d4a6cc0ae72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n",
            "Successfully saved project id\n",
            "Warning: TensorFlow Addons not found. Models that use non-standard ops may not work.\n",
            "Success: model at '/content/drive/MyDrive/RTS_models/Deployed_Models/Unet3_MAXAR192_20230601_161139_EEify' is ready to be hosted in AI Platform.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile config.yaml\n",
        "autoScaling:\n",
        "  minNodes: 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLtnMu3f1_Cn",
        "outputId": "4b6d50e3-58dd-4e58-eec0-0cf02cc7ba16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud ai-platform models create {MODEL_NAME} \\\n",
        "  --project {PROJECT} \\\n",
        "  --region {REGION}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL9734LZr9Pw",
        "outputId": "52f2ef3f-3485-4301-dd9f-511a9985155e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using endpoint [https://us-east4-ml.googleapis.com/]\n",
            "Created ai platform model [projects/abruptthawmapping/models/Unet3_MAXAR192_20230601_161139].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!gcloud ai-platform versions create {VERSION_NAME} \\\n",
        "  --project {PROJECT} \\\n",
        "  --region {REGION} \\\n",
        "  --model {MODEL_NAME} \\\n",
        "  --origin {EEIFIED_DIR} \\\n",
        "  --staging-bucket {STAGING_BUCKET} \\\n",
        "  --framework \"TENSORFLOW\" \\\n",
        "  --runtime-version=2.3 \\\n",
        "  --python-version=3.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLuCab2C2bv2",
        "outputId": "47a039be-89c7-40ed-9115-e97f891a5b4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using endpoint [https://us-east4-ml.googleapis.com/]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model and use it for prediction.  If you specified a region\n",
        "# other than the default (us-central1) at model creation, specify it here.\n",
        "model = ee.Model.fromAiPlatformPredictor(\n",
        "    projectName=PROJECT,\n",
        "    modelName=MODEL_NAME,\n",
        "    version=VERSION_NAME,\n",
        "    region=REGION,\n",
        "    # Can be anything, but don't make it too big.\n",
        "    inputTileSize=[192, 192],\n",
        "    inputOverlapSize=[32,32],\n",
        "    # Keep this the same as your training data.\n",
        "    proj=ee.Projection('EPSG:3413').atScale(2),\n",
        "    fixInputProj=True,\n",
        "    # Note the names here need to match what you specified in the\n",
        "    # output dictionary you passed to the EEifier.\n",
        "    outputBands={'prediction': {\n",
        "        'type': ee.PixelType.float(),\n",
        "        'dimensions': 1\n",
        "      }\n",
        "    },\n",
        ")\n",
        "\n",
        "print(model.getInfo())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkJjd7H24_H4",
        "outputId": "2f73b972-ceb9-4808-b0c3-7863862f960d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'type': 'Model.fromAiPlatformPredictor', 'projectName': 'abruptthawmapping', 'projectId': 'abruptthawmapping', 'modelName': 'Unet3plus_MAXAR192_20230601-161139.tf', 'version': 'v3', 'region': 'us-east4', 'inputProperties': [], 'inputTypeOverride': {}, 'inputShapes': {}, 'proj': {'type': 'Projection', 'crs': 'EPSG:3413', 'transform': [2, 0, 0, 0, 2, 0]}, 'fixInputProj': True, 'inputTileSize': [192, 192], 'inputOverlapSize': [32, 32], 'outputTileSize': [192, 192], 'outputBands': {'prediction': {'type': {'type': 'PixelType', 'precision': 'float', 'dimensions': 1}}}, 'outputProperties': {}, 'outputMultiplier': 1}\n"
          ]
        }
      ]
    }
  ]
}